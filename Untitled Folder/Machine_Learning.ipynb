{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7485270a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>resid_area</th>\n",
       "      <th>air_qual</th>\n",
       "      <th>room_num</th>\n",
       "      <th>age</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>dist3</th>\n",
       "      <th>dist4</th>\n",
       "      <th>teachers</th>\n",
       "      <th>poor_prop</th>\n",
       "      <th>n_hos_beds</th>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>parks</th>\n",
       "      <th>Sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.528854</td>\n",
       "      <td>41.136779</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.971996</td>\n",
       "      <td>3.628775</td>\n",
       "      <td>3.960672</td>\n",
       "      <td>3.618972</td>\n",
       "      <td>21.544466</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>7.899767</td>\n",
       "      <td>13.041605</td>\n",
       "      <td>39.181818</td>\n",
       "      <td>0.054454</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.182176</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.108532</td>\n",
       "      <td>2.108580</td>\n",
       "      <td>2.119797</td>\n",
       "      <td>2.099203</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>1.476683</td>\n",
       "      <td>5.238957</td>\n",
       "      <td>12.513697</td>\n",
       "      <td>0.010632</td>\n",
       "      <td>0.498422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.460000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.268000</td>\n",
       "      <td>10.057600</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.033292</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.025000</td>\n",
       "      <td>35.190000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.270000</td>\n",
       "      <td>1.940000</td>\n",
       "      <td>2.232500</td>\n",
       "      <td>1.940000</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>6.634500</td>\n",
       "      <td>11.189800</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.046464</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.200000</td>\n",
       "      <td>39.690000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.385000</td>\n",
       "      <td>3.010000</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>3.070000</td>\n",
       "      <td>20.950000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>7.999000</td>\n",
       "      <td>12.720000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.053507</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>48.100000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.367500</td>\n",
       "      <td>4.992500</td>\n",
       "      <td>5.407500</td>\n",
       "      <td>4.985000</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>9.088000</td>\n",
       "      <td>14.170800</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.061397</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>57.740000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.320000</td>\n",
       "      <td>11.930000</td>\n",
       "      <td>12.320000</td>\n",
       "      <td>11.940000</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>10.876000</td>\n",
       "      <td>101.120000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.086711</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            price  resid_area    air_qual    room_num         age       dist1  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    22.528854   41.136779    0.554695    6.284634   68.574901    3.971996   \n",
       "std      9.182176    6.860353    0.115878    0.702617   28.148861    2.108532   \n",
       "min      5.000000   30.460000    0.385000    3.561000    2.900000    1.130000   \n",
       "25%     17.025000   35.190000    0.449000    5.885500   45.025000    2.270000   \n",
       "50%     21.200000   39.690000    0.538000    6.208500   77.500000    3.385000   \n",
       "75%     25.000000   48.100000    0.624000    6.623500   94.075000    5.367500   \n",
       "max     50.000000   57.740000    0.871000    8.780000  100.000000   12.320000   \n",
       "\n",
       "            dist2       dist3       dist4    teachers   poor_prop  n_hos_beds  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  498.000000   \n",
       "mean     3.628775    3.960672    3.618972   21.544466   12.653063    7.899767   \n",
       "std      2.108580    2.119797    2.099203    2.164946    7.141062    1.476683   \n",
       "min      0.920000    1.150000    0.730000   18.000000    1.730000    5.268000   \n",
       "25%      1.940000    2.232500    1.940000   19.800000    6.950000    6.634500   \n",
       "50%      3.010000    3.375000    3.070000   20.950000   11.360000    7.999000   \n",
       "75%      4.992500    5.407500    4.985000   22.600000   16.955000    9.088000   \n",
       "max     11.930000   12.320000   11.940000   27.400000   37.970000   10.876000   \n",
       "\n",
       "       n_hot_rooms    rainfall       parks        Sold  \n",
       "count   506.000000  506.000000  506.000000  506.000000  \n",
       "mean     13.041605   39.181818    0.054454    0.454545  \n",
       "std       5.238957   12.513697    0.010632    0.498422  \n",
       "min      10.057600    3.000000    0.033292    0.000000  \n",
       "25%      11.189800   28.000000    0.046464    0.000000  \n",
       "50%      12.720000   39.000000    0.053507    0.000000  \n",
       "75%      14.170800   50.000000    0.061397    1.000000  \n",
       "max     101.120000   60.000000    0.086711    1.000000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('House_Price.csv')\n",
    "df.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac6805a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x2e2e0d09010>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.jointplot(x = 'rainfall', y = 'Sold', data = df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3bbe911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In Collection there is a huge difference between 75% and max value\n",
    "#In Twitter_hastags there is a hugr difference beteween 75% and the max value\n",
    "#So there is in the marketing expense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53947c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "469a1db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 20 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Collection           506 non-null    int64  \n",
      " 1   Marketing expense    506 non-null    float64\n",
      " 2   Production expense   506 non-null    float64\n",
      " 3   Multiplex coverage   506 non-null    float64\n",
      " 4   Budget               506 non-null    float64\n",
      " 5   Movie_length         506 non-null    float64\n",
      " 6   Lead_ Actor_Rating   506 non-null    float64\n",
      " 7   Lead_Actress_rating  506 non-null    float64\n",
      " 8   Director_rating      506 non-null    float64\n",
      " 9   Producer_rating      506 non-null    float64\n",
      " 10  Critic_rating        506 non-null    float64\n",
      " 11  Trailer_views        506 non-null    int64  \n",
      " 12  3D_available         506 non-null    object \n",
      " 13  Time_taken           494 non-null    float64\n",
      " 14  Twitter_hastags      506 non-null    float64\n",
      " 15  Genre                506 non-null    object \n",
      " 16  Avg_age_actors       506 non-null    int64  \n",
      " 17  MPAA_film_rating     506 non-null    object \n",
      " 18  Num_multiplex        506 non-null    int64  \n",
      " 19  Start_Tech_Oscar     506 non-null    int64  \n",
      "dtypes: float64(12), int64(5), object(3)\n",
      "memory usage: 79.2+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 20 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Collection           506 non-null    int64  \n",
      " 1   Marketing expense    506 non-null    float64\n",
      " 2   Production expense   506 non-null    float64\n",
      " 3   Multiplex coverage   506 non-null    float64\n",
      " 4   Budget               506 non-null    float64\n",
      " 5   Movie_length         506 non-null    float64\n",
      " 6   Lead_ Actor_Rating   506 non-null    float64\n",
      " 7   Lead_Actress_rating  506 non-null    float64\n",
      " 8   Director_rating      506 non-null    float64\n",
      " 9   Producer_rating      506 non-null    float64\n",
      " 10  Critic_rating        506 non-null    float64\n",
      " 11  Trailer_views        506 non-null    int64  \n",
      " 12  3D_available         506 non-null    object \n",
      " 13  Time_taken           506 non-null    float64\n",
      " 14  Twitter_hastags      506 non-null    float64\n",
      " 15  Genre                506 non-null    object \n",
      " 16  Avg_age_actors       506 non-null    int64  \n",
      " 17  MPAA_film_rating     506 non-null    object \n",
      " 18  Num_multiplex        506 non-null    int64  \n",
      " 19  Start_Tech_Oscar     506 non-null    int64  \n",
      "dtypes: float64(12), int64(5), object(3)\n",
      "memory usage: 79.2+ KB\n"
     ]
    }
   ],
   "source": [
    "movie_data = pd.read_csv('Movie_collection.csv')\n",
    "\n",
    "movie_data.info()\n",
    "movie_data.head()\n",
    "\n",
    "\n",
    "movie_data.Time_taken = movie_data.Time_taken.fillna(movie_data.Time_taken.mean())\n",
    "movie_data.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "535d135b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Collection</th>\n",
       "      <th>Marketing expense</th>\n",
       "      <th>Production expense</th>\n",
       "      <th>Multiplex coverage</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Movie_length</th>\n",
       "      <th>Lead_ Actor_Rating</th>\n",
       "      <th>Lead_Actress_rating</th>\n",
       "      <th>Director_rating</th>\n",
       "      <th>Producer_rating</th>\n",
       "      <th>Critic_rating</th>\n",
       "      <th>Trailer_views</th>\n",
       "      <th>Time_taken</th>\n",
       "      <th>Twitter_hastags</th>\n",
       "      <th>Avg_age_actors</th>\n",
       "      <th>Num_multiplex</th>\n",
       "      <th>Start_Tech_Oscar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45057.707510</td>\n",
       "      <td>92.270471</td>\n",
       "      <td>77.273557</td>\n",
       "      <td>0.445305</td>\n",
       "      <td>34911.144022</td>\n",
       "      <td>142.074901</td>\n",
       "      <td>8.014002</td>\n",
       "      <td>8.185613</td>\n",
       "      <td>8.019664</td>\n",
       "      <td>8.190514</td>\n",
       "      <td>7.810870</td>\n",
       "      <td>449860.715415</td>\n",
       "      <td>157.391498</td>\n",
       "      <td>260.832095</td>\n",
       "      <td>39.181818</td>\n",
       "      <td>545.043478</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18364.351764</td>\n",
       "      <td>172.030902</td>\n",
       "      <td>13.720706</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>3903.038232</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>1.054266</td>\n",
       "      <td>1.054290</td>\n",
       "      <td>1.059899</td>\n",
       "      <td>1.049601</td>\n",
       "      <td>0.659699</td>\n",
       "      <td>68917.763145</td>\n",
       "      <td>30.921101</td>\n",
       "      <td>104.779133</td>\n",
       "      <td>12.513697</td>\n",
       "      <td>106.332889</td>\n",
       "      <td>0.498422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>20.126400</td>\n",
       "      <td>55.920000</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>19781.355000</td>\n",
       "      <td>76.400000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>4.035000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>212912.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>201.152000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34050.000000</td>\n",
       "      <td>21.640900</td>\n",
       "      <td>65.380000</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>32693.952500</td>\n",
       "      <td>118.525000</td>\n",
       "      <td>7.316250</td>\n",
       "      <td>7.503750</td>\n",
       "      <td>7.296250</td>\n",
       "      <td>7.507500</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>409128.000000</td>\n",
       "      <td>132.690000</td>\n",
       "      <td>223.796000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>465.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>42400.000000</td>\n",
       "      <td>25.130200</td>\n",
       "      <td>74.380000</td>\n",
       "      <td>0.462000</td>\n",
       "      <td>34488.217500</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>8.307500</td>\n",
       "      <td>8.495000</td>\n",
       "      <td>8.312500</td>\n",
       "      <td>8.465000</td>\n",
       "      <td>7.960000</td>\n",
       "      <td>462460.000000</td>\n",
       "      <td>158.980000</td>\n",
       "      <td>254.400000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>535.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>93.541650</td>\n",
       "      <td>91.200000</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>36793.542500</td>\n",
       "      <td>167.575000</td>\n",
       "      <td>8.865000</td>\n",
       "      <td>9.030000</td>\n",
       "      <td>8.883750</td>\n",
       "      <td>9.030000</td>\n",
       "      <td>8.260000</td>\n",
       "      <td>500247.500000</td>\n",
       "      <td>181.520000</td>\n",
       "      <td>283.416000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>614.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1799.524000</td>\n",
       "      <td>110.480000</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>48772.900000</td>\n",
       "      <td>173.500000</td>\n",
       "      <td>9.435000</td>\n",
       "      <td>9.540000</td>\n",
       "      <td>9.425000</td>\n",
       "      <td>9.635000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>567784.000000</td>\n",
       "      <td>217.520000</td>\n",
       "      <td>2022.400000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>868.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Collection  Marketing expense  Production expense  \\\n",
       "count     506.000000         506.000000          506.000000   \n",
       "mean    45057.707510          92.270471           77.273557   \n",
       "std     18364.351764         172.030902           13.720706   \n",
       "min     10000.000000          20.126400           55.920000   \n",
       "25%     34050.000000          21.640900           65.380000   \n",
       "50%     42400.000000          25.130200           74.380000   \n",
       "75%     50000.000000          93.541650           91.200000   \n",
       "max    100000.000000        1799.524000          110.480000   \n",
       "\n",
       "       Multiplex coverage        Budget  Movie_length  Lead_ Actor_Rating  \\\n",
       "count          506.000000    506.000000    506.000000          506.000000   \n",
       "mean             0.445305  34911.144022    142.074901            8.014002   \n",
       "std              0.115878   3903.038232     28.148861            1.054266   \n",
       "min              0.129000  19781.355000     76.400000            3.840000   \n",
       "25%              0.376000  32693.952500    118.525000            7.316250   \n",
       "50%              0.462000  34488.217500    151.000000            8.307500   \n",
       "75%              0.551000  36793.542500    167.575000            8.865000   \n",
       "max              0.615000  48772.900000    173.500000            9.435000   \n",
       "\n",
       "       Lead_Actress_rating  Director_rating  Producer_rating  Critic_rating  \\\n",
       "count           506.000000       506.000000       506.000000     506.000000   \n",
       "mean              8.185613         8.019664         8.190514       7.810870   \n",
       "std               1.054290         1.059899         1.049601       0.659699   \n",
       "min               4.035000         3.840000         4.030000       6.600000   \n",
       "25%               7.503750         7.296250         7.507500       7.200000   \n",
       "50%               8.495000         8.312500         8.465000       7.960000   \n",
       "75%               9.030000         8.883750         9.030000       8.260000   \n",
       "max               9.540000         9.425000         9.635000       9.400000   \n",
       "\n",
       "       Trailer_views  Time_taken  Twitter_hastags  Avg_age_actors  \\\n",
       "count     506.000000  506.000000       506.000000      506.000000   \n",
       "mean   449860.715415  157.391498       260.832095       39.181818   \n",
       "std     68917.763145   30.921101       104.779133       12.513697   \n",
       "min    212912.000000    0.000000       201.152000        3.000000   \n",
       "25%    409128.000000  132.690000       223.796000       28.000000   \n",
       "50%    462460.000000  158.980000       254.400000       39.000000   \n",
       "75%    500247.500000  181.520000       283.416000       50.000000   \n",
       "max    567784.000000  217.520000      2022.400000       60.000000   \n",
       "\n",
       "       Num_multiplex  Start_Tech_Oscar  \n",
       "count     506.000000        506.000000  \n",
       "mean      545.043478          0.454545  \n",
       "std       106.332889          0.498422  \n",
       "min       333.000000          0.000000  \n",
       "25%       465.000000          0.000000  \n",
       "50%       535.500000          0.000000  \n",
       "75%       614.750000          1.000000  \n",
       "max       868.000000          1.000000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "718d6631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreer\\AppData\\Local\\Temp\\ipykernel_6588\\352957441.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['3D_available'] = X['3D_available'].map({'YES': 1, 'NO': 0})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Collection</th>\n",
       "      <th>Marketing expense</th>\n",
       "      <th>Production expense</th>\n",
       "      <th>Multiplex coverage</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Movie_length</th>\n",
       "      <th>Lead_ Actor_Rating</th>\n",
       "      <th>Lead_Actress_rating</th>\n",
       "      <th>Director_rating</th>\n",
       "      <th>Producer_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>Trailer_views</th>\n",
       "      <th>3D_available</th>\n",
       "      <th>Time_taken</th>\n",
       "      <th>Twitter_hastags</th>\n",
       "      <th>Avg_age_actors</th>\n",
       "      <th>Num_multiplex</th>\n",
       "      <th>Start_Tech_Oscar</th>\n",
       "      <th>Genre_Comedy</th>\n",
       "      <th>Genre_Drama</th>\n",
       "      <th>Genre_Thriller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48000</td>\n",
       "      <td>20.1264</td>\n",
       "      <td>59.62</td>\n",
       "      <td>0.462</td>\n",
       "      <td>36524.125</td>\n",
       "      <td>138.7</td>\n",
       "      <td>7.825</td>\n",
       "      <td>8.095</td>\n",
       "      <td>7.910</td>\n",
       "      <td>7.995</td>\n",
       "      <td>...</td>\n",
       "      <td>527367</td>\n",
       "      <td>YES</td>\n",
       "      <td>109.60</td>\n",
       "      <td>223.840</td>\n",
       "      <td>23</td>\n",
       "      <td>494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43200</td>\n",
       "      <td>20.5462</td>\n",
       "      <td>69.14</td>\n",
       "      <td>0.531</td>\n",
       "      <td>35668.655</td>\n",
       "      <td>152.4</td>\n",
       "      <td>7.505</td>\n",
       "      <td>7.650</td>\n",
       "      <td>7.440</td>\n",
       "      <td>7.470</td>\n",
       "      <td>...</td>\n",
       "      <td>494055</td>\n",
       "      <td>NO</td>\n",
       "      <td>146.64</td>\n",
       "      <td>243.456</td>\n",
       "      <td>42</td>\n",
       "      <td>462</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69400</td>\n",
       "      <td>20.5458</td>\n",
       "      <td>69.14</td>\n",
       "      <td>0.531</td>\n",
       "      <td>39912.675</td>\n",
       "      <td>134.6</td>\n",
       "      <td>7.485</td>\n",
       "      <td>7.570</td>\n",
       "      <td>7.495</td>\n",
       "      <td>7.515</td>\n",
       "      <td>...</td>\n",
       "      <td>547051</td>\n",
       "      <td>NO</td>\n",
       "      <td>147.88</td>\n",
       "      <td>2022.400</td>\n",
       "      <td>38</td>\n",
       "      <td>458</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66800</td>\n",
       "      <td>20.6474</td>\n",
       "      <td>59.36</td>\n",
       "      <td>0.542</td>\n",
       "      <td>38873.890</td>\n",
       "      <td>119.3</td>\n",
       "      <td>6.895</td>\n",
       "      <td>7.035</td>\n",
       "      <td>6.920</td>\n",
       "      <td>7.020</td>\n",
       "      <td>...</td>\n",
       "      <td>516279</td>\n",
       "      <td>YES</td>\n",
       "      <td>185.36</td>\n",
       "      <td>225.344</td>\n",
       "      <td>45</td>\n",
       "      <td>472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72400</td>\n",
       "      <td>21.3810</td>\n",
       "      <td>59.36</td>\n",
       "      <td>0.542</td>\n",
       "      <td>39701.585</td>\n",
       "      <td>127.7</td>\n",
       "      <td>6.920</td>\n",
       "      <td>7.070</td>\n",
       "      <td>6.815</td>\n",
       "      <td>7.070</td>\n",
       "      <td>...</td>\n",
       "      <td>531448</td>\n",
       "      <td>NO</td>\n",
       "      <td>176.48</td>\n",
       "      <td>225.792</td>\n",
       "      <td>55</td>\n",
       "      <td>395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>44800</td>\n",
       "      <td>21.2526</td>\n",
       "      <td>78.86</td>\n",
       "      <td>0.427</td>\n",
       "      <td>36624.115</td>\n",
       "      <td>142.6</td>\n",
       "      <td>8.680</td>\n",
       "      <td>8.775</td>\n",
       "      <td>8.620</td>\n",
       "      <td>8.970</td>\n",
       "      <td>...</td>\n",
       "      <td>492480</td>\n",
       "      <td>NO</td>\n",
       "      <td>186.96</td>\n",
       "      <td>243.584</td>\n",
       "      <td>27</td>\n",
       "      <td>561</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>41200</td>\n",
       "      <td>20.9054</td>\n",
       "      <td>78.86</td>\n",
       "      <td>0.427</td>\n",
       "      <td>33996.600</td>\n",
       "      <td>150.2</td>\n",
       "      <td>8.780</td>\n",
       "      <td>8.945</td>\n",
       "      <td>8.770</td>\n",
       "      <td>8.930</td>\n",
       "      <td>...</td>\n",
       "      <td>482875</td>\n",
       "      <td>YES</td>\n",
       "      <td>132.24</td>\n",
       "      <td>263.296</td>\n",
       "      <td>20</td>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>47800</td>\n",
       "      <td>21.2152</td>\n",
       "      <td>78.86</td>\n",
       "      <td>0.427</td>\n",
       "      <td>38751.680</td>\n",
       "      <td>164.5</td>\n",
       "      <td>8.830</td>\n",
       "      <td>8.970</td>\n",
       "      <td>8.855</td>\n",
       "      <td>9.010</td>\n",
       "      <td>...</td>\n",
       "      <td>532239</td>\n",
       "      <td>NO</td>\n",
       "      <td>109.56</td>\n",
       "      <td>243.824</td>\n",
       "      <td>31</td>\n",
       "      <td>576</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>44000</td>\n",
       "      <td>22.1918</td>\n",
       "      <td>78.86</td>\n",
       "      <td>0.427</td>\n",
       "      <td>37740.670</td>\n",
       "      <td>162.8</td>\n",
       "      <td>8.730</td>\n",
       "      <td>8.845</td>\n",
       "      <td>8.800</td>\n",
       "      <td>8.845</td>\n",
       "      <td>...</td>\n",
       "      <td>496077</td>\n",
       "      <td>YES</td>\n",
       "      <td>158.80</td>\n",
       "      <td>303.520</td>\n",
       "      <td>47</td>\n",
       "      <td>607</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>38000</td>\n",
       "      <td>20.9482</td>\n",
       "      <td>78.86</td>\n",
       "      <td>0.427</td>\n",
       "      <td>33496.650</td>\n",
       "      <td>154.3</td>\n",
       "      <td>8.640</td>\n",
       "      <td>8.880</td>\n",
       "      <td>8.680</td>\n",
       "      <td>8.790</td>\n",
       "      <td>...</td>\n",
       "      <td>518438</td>\n",
       "      <td>YES</td>\n",
       "      <td>205.60</td>\n",
       "      <td>203.040</td>\n",
       "      <td>45</td>\n",
       "      <td>604</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Collection  Marketing expense  Production expense  Multiplex coverage  \\\n",
       "0         48000            20.1264               59.62               0.462   \n",
       "1         43200            20.5462               69.14               0.531   \n",
       "2         69400            20.5458               69.14               0.531   \n",
       "3         66800            20.6474               59.36               0.542   \n",
       "4         72400            21.3810               59.36               0.542   \n",
       "..          ...                ...                 ...                 ...   \n",
       "501       44800            21.2526               78.86               0.427   \n",
       "502       41200            20.9054               78.86               0.427   \n",
       "503       47800            21.2152               78.86               0.427   \n",
       "504       44000            22.1918               78.86               0.427   \n",
       "505       38000            20.9482               78.86               0.427   \n",
       "\n",
       "        Budget  Movie_length  Lead_ Actor_Rating  Lead_Actress_rating  \\\n",
       "0    36524.125         138.7               7.825                8.095   \n",
       "1    35668.655         152.4               7.505                7.650   \n",
       "2    39912.675         134.6               7.485                7.570   \n",
       "3    38873.890         119.3               6.895                7.035   \n",
       "4    39701.585         127.7               6.920                7.070   \n",
       "..         ...           ...                 ...                  ...   \n",
       "501  36624.115         142.6               8.680                8.775   \n",
       "502  33996.600         150.2               8.780                8.945   \n",
       "503  38751.680         164.5               8.830                8.970   \n",
       "504  37740.670         162.8               8.730                8.845   \n",
       "505  33496.650         154.3               8.640                8.880   \n",
       "\n",
       "     Director_rating  Producer_rating  ...  Trailer_views  3D_available  \\\n",
       "0              7.910            7.995  ...         527367           YES   \n",
       "1              7.440            7.470  ...         494055            NO   \n",
       "2              7.495            7.515  ...         547051            NO   \n",
       "3              6.920            7.020  ...         516279           YES   \n",
       "4              6.815            7.070  ...         531448            NO   \n",
       "..               ...              ...  ...            ...           ...   \n",
       "501            8.620            8.970  ...         492480            NO   \n",
       "502            8.770            8.930  ...         482875           YES   \n",
       "503            8.855            9.010  ...         532239            NO   \n",
       "504            8.800            8.845  ...         496077           YES   \n",
       "505            8.680            8.790  ...         518438           YES   \n",
       "\n",
       "    Time_taken  Twitter_hastags  Avg_age_actors  Num_multiplex  \\\n",
       "0       109.60          223.840              23            494   \n",
       "1       146.64          243.456              42            462   \n",
       "2       147.88         2022.400              38            458   \n",
       "3       185.36          225.344              45            472   \n",
       "4       176.48          225.792              55            395   \n",
       "..         ...              ...             ...            ...   \n",
       "501     186.96          243.584              27            561   \n",
       "502     132.24          263.296              20            600   \n",
       "503     109.56          243.824              31            576   \n",
       "504     158.80          303.520              47            607   \n",
       "505     205.60          203.040              45            604   \n",
       "\n",
       "     Start_Tech_Oscar  Genre_Comedy  Genre_Drama  Genre_Thriller  \n",
       "0                   0             0            0               1  \n",
       "1                   1             0            1               0  \n",
       "2                   0             1            0               0  \n",
       "3                   0             0            1               0  \n",
       "4                   0             0            1               0  \n",
       "..                ...           ...          ...             ...  \n",
       "501                 1             0            0               0  \n",
       "502                 1             0            0               0  \n",
       "503                 1             1            0               0  \n",
       "504                 1             1            0               0  \n",
       "505                 1             1            0               0  \n",
       "\n",
       "[506 rows x 21 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(movie_data)\n",
    "X['3D_available'] = X['3D_available'].map({'YES': 1, 'NO': 0})\n",
    "movie_data = pd.get_dummies(movie_data, columns=['Genre'], drop_first=True)\n",
    "movie_data = pd.get_dummies(movie_data, columns=['MPAA_film_rating'], drop_first=True)\n",
    "\n",
    "\n",
    "movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eabdc1ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['3D_available'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m movie_data\u001b[38;5;241m.\u001b[39mloc[:,movie_data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBudget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m movie_data \u001b[38;5;241m=\u001b[39m movie_data\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3D_available\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduction expense\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m movie_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBudget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m X\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5251\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   5252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5262\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5263\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5264\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5397\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5400\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5401\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5402\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5403\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5404\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5405\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5406\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5407\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6935\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6936\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['3D_available'] not found in axis\""
     ]
    }
   ],
   "source": [
    "X = movie_data.loc[:,movie_data.columns != 'Budget']\n",
    "movie_data = movie_data.drop(['3D_available', 'Production expense'], axis=1)\n",
    "\n",
    "y = movie_data['Budget']\n",
    "\n",
    "X.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35dcf2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36524.125\n",
       "1    35668.655\n",
       "2    39912.675\n",
       "3    38873.890\n",
       "4    39701.585\n",
       "Name: Budget, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca9aa2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.30517082e-01,  2.54148005e+00, -3.23209620e+01, -4.42427759e+03,\n",
       "        2.58556616e+01, -2.82958795e+03,  9.83628391e+02,  2.12356108e+03,\n",
       "       -6.87633387e+02, -6.37185997e+01,  1.39414393e-02, -5.73407604e+00,\n",
       "        1.01172829e+00, -1.37283578e+01, -1.74658312e+00,  9.09216670e+02,\n",
       "       -4.75475919e+02, -6.57061171e+02, -6.55736735e+02])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "cls = LinearRegression()\n",
    "cls.fit(X,y)\n",
    "cls.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cls.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49507ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Budget</td>      <th>  R-squared:         </th> <td>   0.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   31.71</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 30 Sep 2023</td> <th>  Prob (F-statistic):</th> <td>1.02e-72</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:32:38</td>     <th>  Log-Likelihood:    </th> <td> -4697.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   9436.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   486</td>      <th>  BIC:               </th> <td>   9520.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td> 2.927e+04</td> <td> 4476.818</td> <td>    6.537</td> <td> 0.000</td> <td> 2.05e+04</td> <td> 3.81e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Collection</th>          <td>    0.1305</td> <td>    0.011</td> <td>   11.870</td> <td> 0.000</td> <td>    0.109</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Marketing expense</th>   <td>    2.5415</td> <td>    0.803</td> <td>    3.166</td> <td> 0.002</td> <td>    0.964</td> <td>    4.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Production expense</th>  <td>  -32.3210</td> <td>   15.071</td> <td>   -2.145</td> <td> 0.032</td> <td>  -61.933</td> <td>   -2.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Multiplex coverage</th>  <td>-4424.2776</td> <td> 3043.730</td> <td>   -1.454</td> <td> 0.147</td> <td>-1.04e+04</td> <td> 1556.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Movie_length</th>        <td>   25.8557</td> <td>    7.210</td> <td>    3.586</td> <td> 0.000</td> <td>   11.690</td> <td>   40.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lead_ Actor_Rating</th>  <td>-2829.5880</td> <td> 1998.147</td> <td>   -1.416</td> <td> 0.157</td> <td>-6755.662</td> <td> 1096.486</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lead_Actress_rating</th> <td>  983.6284</td> <td> 2142.715</td> <td>    0.459</td> <td> 0.646</td> <td>-3226.501</td> <td> 5193.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Director_rating</th>     <td> 2123.5611</td> <td> 2080.538</td> <td>    1.021</td> <td> 0.308</td> <td>-1964.399</td> <td> 6211.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Producer_rating</th>     <td> -687.6334</td> <td> 1122.524</td> <td>   -0.613</td> <td> 0.540</td> <td>-2893.233</td> <td> 1517.966</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Critic_rating</th>       <td>  -63.7186</td> <td>  198.125</td> <td>   -0.322</td> <td> 0.748</td> <td> -453.006</td> <td>  325.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Trailer_views</th>       <td>    0.0139</td> <td>    0.003</td> <td>    4.525</td> <td> 0.000</td> <td>    0.008</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time_taken</th>          <td>   -5.7341</td> <td>    3.971</td> <td>   -1.444</td> <td> 0.149</td> <td>  -13.537</td> <td>    2.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Twitter_hastags</th>     <td>    1.0117</td> <td>    1.141</td> <td>    0.887</td> <td> 0.376</td> <td>   -1.231</td> <td>    3.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Avg_age_actors</th>      <td>  -13.7284</td> <td>    9.663</td> <td>   -1.421</td> <td> 0.156</td> <td>  -32.714</td> <td>    5.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Num_multiplex</th>       <td>   -1.7466</td> <td>    2.794</td> <td>   -0.625</td> <td> 0.532</td> <td>   -7.237</td> <td>    3.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Start_Tech_Oscar</th>    <td>  909.2167</td> <td>  258.716</td> <td>    3.514</td> <td> 0.000</td> <td>  400.876</td> <td> 1417.557</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Genre_Comedy</th>        <td> -475.4759</td> <td>  386.522</td> <td>   -1.230</td> <td> 0.219</td> <td>-1234.936</td> <td>  283.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Genre_Drama</th>         <td> -657.0612</td> <td>  421.425</td> <td>   -1.559</td> <td> 0.120</td> <td>-1485.101</td> <td>  170.978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Genre_Thriller</th>      <td> -655.7367</td> <td>  379.216</td> <td>   -1.729</td> <td> 0.084</td> <td>-1400.841</td> <td>   89.368</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>145.102</td> <th>  Durbin-Watson:     </th> <td>   1.288</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1399.659</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.951</td>  <th>  Prob(JB):          </th> <td>1.17e-304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.923</td>  <th>  Cond. No.          </th> <td>2.00e+07</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large,  2e+07. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}        &      Budget      & \\textbf{  R-squared:         } &     0.554   \\\\\n",
       "\\textbf{Model:}                &       OLS        & \\textbf{  Adj. R-squared:    } &     0.536   \\\\\n",
       "\\textbf{Method:}               &  Least Squares   & \\textbf{  F-statistic:       } &     31.71   \\\\\n",
       "\\textbf{Date:}                 & Sat, 30 Sep 2023 & \\textbf{  Prob (F-statistic):} &  1.02e-72   \\\\\n",
       "\\textbf{Time:}                 &     20:32:38     & \\textbf{  Log-Likelihood:    } &   -4697.9   \\\\\n",
       "\\textbf{No. Observations:}     &         506      & \\textbf{  AIC:               } &     9436.   \\\\\n",
       "\\textbf{Df Residuals:}         &         486      & \\textbf{  BIC:               } &     9520.   \\\\\n",
       "\\textbf{Df Model:}             &          19      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}      &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                 &    2.927e+04  &     4476.818     &     6.537  &         0.000        &     2.05e+04    &     3.81e+04     \\\\\n",
       "\\textbf{Collection}            &       0.1305  &        0.011     &    11.870  &         0.000        &        0.109    &        0.152     \\\\\n",
       "\\textbf{Marketing expense}     &       2.5415  &        0.803     &     3.166  &         0.002        &        0.964    &        4.119     \\\\\n",
       "\\textbf{Production expense}    &     -32.3210  &       15.071     &    -2.145  &         0.032        &      -61.933    &       -2.709     \\\\\n",
       "\\textbf{Multiplex coverage}    &   -4424.2776  &     3043.730     &    -1.454  &         0.147        &    -1.04e+04    &     1556.218     \\\\\n",
       "\\textbf{Movie\\_length}         &      25.8557  &        7.210     &     3.586  &         0.000        &       11.690    &       40.022     \\\\\n",
       "\\textbf{Lead\\_ Actor\\_Rating}  &   -2829.5880  &     1998.147     &    -1.416  &         0.157        &    -6755.662    &     1096.486     \\\\\n",
       "\\textbf{Lead\\_Actress\\_rating} &     983.6284  &     2142.715     &     0.459  &         0.646        &    -3226.501    &     5193.758     \\\\\n",
       "\\textbf{Director\\_rating}      &    2123.5611  &     2080.538     &     1.021  &         0.308        &    -1964.399    &     6211.521     \\\\\n",
       "\\textbf{Producer\\_rating}      &    -687.6334  &     1122.524     &    -0.613  &         0.540        &    -2893.233    &     1517.966     \\\\\n",
       "\\textbf{Critic\\_rating}        &     -63.7186  &      198.125     &    -0.322  &         0.748        &     -453.006    &      325.568     \\\\\n",
       "\\textbf{Trailer\\_views}        &       0.0139  &        0.003     &     4.525  &         0.000        &        0.008    &        0.020     \\\\\n",
       "\\textbf{Time\\_taken}           &      -5.7341  &        3.971     &    -1.444  &         0.149        &      -13.537    &        2.069     \\\\\n",
       "\\textbf{Twitter\\_hastags}      &       1.0117  &        1.141     &     0.887  &         0.376        &       -1.231    &        3.254     \\\\\n",
       "\\textbf{Avg\\_age\\_actors}      &     -13.7284  &        9.663     &    -1.421  &         0.156        &      -32.714    &        5.257     \\\\\n",
       "\\textbf{Num\\_multiplex}        &      -1.7466  &        2.794     &    -0.625  &         0.532        &       -7.237    &        3.744     \\\\\n",
       "\\textbf{Start\\_Tech\\_Oscar}    &     909.2167  &      258.716     &     3.514  &         0.000        &      400.876    &     1417.557     \\\\\n",
       "\\textbf{Genre\\_Comedy}         &    -475.4759  &      386.522     &    -1.230  &         0.219        &    -1234.936    &      283.984     \\\\\n",
       "\\textbf{Genre\\_Drama}          &    -657.0612  &      421.425     &    -1.559  &         0.120        &    -1485.101    &      170.978     \\\\\n",
       "\\textbf{Genre\\_Thriller}       &    -655.7367  &      379.216     &    -1.729  &         0.084        &    -1400.841    &       89.368     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 145.102 & \\textbf{  Durbin-Watson:     } &     1.288  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  1399.659  \\\\\n",
       "\\textbf{Skew:}          &  -0.951 & \\textbf{  Prob(JB):          } & 1.17e-304  \\\\\n",
       "\\textbf{Kurtosis:}      &  10.923 & \\textbf{  Cond. No.          } &  2.00e+07  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large,  2e+07. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Budget   R-squared:                       0.554\n",
       "Model:                            OLS   Adj. R-squared:                  0.536\n",
       "Method:                 Least Squares   F-statistic:                     31.71\n",
       "Date:                Sat, 30 Sep 2023   Prob (F-statistic):           1.02e-72\n",
       "Time:                        20:32:38   Log-Likelihood:                -4697.9\n",
       "No. Observations:                 506   AIC:                             9436.\n",
       "Df Residuals:                     486   BIC:                             9520.\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                2.927e+04   4476.818      6.537      0.000    2.05e+04    3.81e+04\n",
       "Collection              0.1305      0.011     11.870      0.000       0.109       0.152\n",
       "Marketing expense       2.5415      0.803      3.166      0.002       0.964       4.119\n",
       "Production expense    -32.3210     15.071     -2.145      0.032     -61.933      -2.709\n",
       "Multiplex coverage  -4424.2776   3043.730     -1.454      0.147   -1.04e+04    1556.218\n",
       "Movie_length           25.8557      7.210      3.586      0.000      11.690      40.022\n",
       "Lead_ Actor_Rating  -2829.5880   1998.147     -1.416      0.157   -6755.662    1096.486\n",
       "Lead_Actress_rating   983.6284   2142.715      0.459      0.646   -3226.501    5193.758\n",
       "Director_rating      2123.5611   2080.538      1.021      0.308   -1964.399    6211.521\n",
       "Producer_rating      -687.6334   1122.524     -0.613      0.540   -2893.233    1517.966\n",
       "Critic_rating         -63.7186    198.125     -0.322      0.748    -453.006     325.568\n",
       "Trailer_views           0.0139      0.003      4.525      0.000       0.008       0.020\n",
       "Time_taken             -5.7341      3.971     -1.444      0.149     -13.537       2.069\n",
       "Twitter_hastags         1.0117      1.141      0.887      0.376      -1.231       3.254\n",
       "Avg_age_actors        -13.7284      9.663     -1.421      0.156     -32.714       5.257\n",
       "Num_multiplex          -1.7466      2.794     -0.625      0.532      -7.237       3.744\n",
       "Start_Tech_Oscar      909.2167    258.716      3.514      0.000     400.876    1417.557\n",
       "Genre_Comedy         -475.4759    386.522     -1.230      0.219   -1234.936     283.984\n",
       "Genre_Drama          -657.0612    421.425     -1.559      0.120   -1485.101     170.978\n",
       "Genre_Thriller       -655.7367    379.216     -1.729      0.084   -1400.841      89.368\n",
       "==============================================================================\n",
       "Omnibus:                      145.102   Durbin-Watson:                   1.288\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1399.659\n",
       "Skew:                          -0.951   Prob(JB):                    1.17e-304\n",
       "Kurtosis:                      10.923   Cond. No.                     2.00e+07\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large,  2e+07. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Add a constant (intercept) to the X variables\n",
    "X_const = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "lm = sm.OLS(y, X_const).fit()\n",
    "\n",
    "# Get the summary of the linear regression model\n",
    "lm_summary = lm.summary()\n",
    "\n",
    "# Print the model summary\n",
    "lm_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4e044928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "cls = LinearDiscriminantAnalysis()\n",
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e86891eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([36524.125, 35668.655, 39912.675, 38873.89 , 39701.585, 35718.65 ,\n       33396.66 , 34285.46 , 31280.205, 33352.22 , 35424.235, 33379.995,\n       32713.395, 33046.695, 33863.28 , 32407.87 , 32968.925, 33274.45 ,\n       30308.08 , 31813.485, 30941.35 , 33135.575, 34118.81 , 32291.215,\n       32907.82 , 31102.445, 32291.215, 33591.085, 36079.725, 37074.07 ,\n       31735.715, 33729.96 , 33052.25 , 31669.055, 33863.28 , 32957.815,\n       32446.755, 32496.75 , 33141.13 , 36635.225, 39018.32 , 37607.35 ,\n       34268.795, 34502.105, 33713.295, 31563.51 , 32141.23 , 33496.65 ,\n       29991.445, 31119.11 , 33124.465, 33968.825, 36168.605, 33318.89 ,\n       32707.84 , 40268.195, 35457.565, 37862.88 , 34135.475, 32924.485,\n       31891.255, 33141.13 , 35863.08 , 37562.91 , 39462.72 , 34940.95 ,\n       32146.785, 32652.29 , 31074.67 , 32691.175, 35646.435, 33113.355,\n       33691.075, 34690.975, 34846.515, 34918.73 , 34879.845, 34107.7  ,\n       34618.76 , 32630.07 , 37368.485, 36768.545, 35007.61 , 34257.685,\n       35490.895, 36829.65 , 33413.325, 34002.155, 38923.885, 39323.845,\n       35646.435, 35579.775, 35785.31 , 34502.105, 34713.195, 36801.875,\n       34235.465, 44823.295, 43440.1  , 41195.88 , 37368.485, 37668.455,\n       35579.775, 34091.035, 34257.685, 32502.305, 32418.98 , 34035.485,\n       35963.07 , 34602.095, 34413.225, 37301.825, 32846.715, 33841.06 ,\n       34740.97 , 32930.04 , 34307.68 , 33446.655, 32618.96 , 31835.705,\n       32607.85 , 33352.22 , 33113.355, 32530.08 , 32657.845, 33252.23 ,\n       31180.215, 31624.615, 35724.205, 31313.535, 35874.19 , 35140.93 ,\n       35396.46 , 32341.21 , 31980.135, 35190.925, 33007.81 , 35851.97 ,\n       32535.635, 34168.805, 34296.57 , 27880.545, 30013.665, 30374.74 ,\n       27236.165, 34052.15 , 31263.54 , 27363.93 , 28808.23 , 31091.335,\n       34007.71 , 30019.22 , 27841.66 , 31713.495, 34046.595, 34174.36 ,\n       29285.96 , 38568.365, 33696.63 , 36163.05 , 34718.75 , 41601.395,\n       43340.11 , 46523.125, 32518.97 , 33891.055, 44045.595, 32646.735,\n       35102.045, 35563.11 , 32635.625, 32663.4  , 30952.46 , 35640.88 ,\n       32546.745, 36363.03 , 33441.1  , 35079.825, 38107.3  , 38773.9  ,\n       43134.575, 34129.92 , 39746.025, 36457.465, 31130.22 , 34179.915,\n       43501.205, 37674.01 , 36418.58 , 39912.675, 38612.805, 37435.145,\n       39873.79 , 37774.   , 36685.22 , 43745.625, 40479.285, 39479.385,\n       40407.07 , 38746.125, 39634.925, 34229.91 , 42273.55 , 43623.415,\n       44628.87 , 32724.505, 35140.93 , 32124.565, 33685.52 , 29685.92 ,\n       33107.8  , 30019.22 , 32257.885, 35413.125, 30063.66 , 34341.01 ,\n       32707.84 , 36896.31 , 33057.805, 35402.015, 38612.805, 34241.02 ,\n       38212.845, 36762.99 , 45917.63 , 48467.375, 44662.2  , 39790.465,\n       42695.73 , 36396.36 , 33224.455, 41173.66 , 46312.035, 45812.085,\n       37362.93 , 33807.73 , 36835.205, 40873.69 , 36001.955, 36696.33 ,\n       38312.835, 33857.725, 35318.69 , 35513.115, 31069.115, 31135.775,\n       33929.94 , 34585.43 , 35735.315, 37318.49 , 36035.285, 35763.09 ,\n       38646.135, 45878.745, 33929.94 , 32641.18 , 41406.97 , 48350.72 ,\n       40734.815, 38007.31 , 40012.665, 41773.6  , 46650.89 , 40701.485,\n       40029.33 , 30885.8  , 38962.77 , 46089.835, 41495.85 , 32885.6  ,\n       32530.08 , 34663.2  , 36318.59 , 42723.505, 37540.69 , 38073.97 ,\n       40368.185, 37918.43 , 36007.51 , 37840.66 , 43440.1  , 38707.24 ,\n       42467.975, 44012.265, 39373.84 , 35846.415, 34607.65 , 34490.995,\n       35079.825, 36468.575, 38112.855, 39707.14 , 36829.65 , 34035.485,\n       33379.995, 37096.29 , 36379.695, 32163.45 , 35246.475, 39112.755,\n       38168.405, 36607.45 , 36079.725, 38785.01 , 40195.98 , 36751.88 ,\n       41218.1  , 38046.195, 36857.425, 33174.46 , 27625.015, 34007.71 ,\n       33457.765, 34807.63 , 36479.685, 31691.275, 32852.27 , 32119.01 ,\n       35452.01 , 33957.715, 35696.43 , 35418.68 , 33557.755, 31707.94 ,\n       35635.325, 35724.205, 35063.16 , 33791.065, 32596.74 , 35179.815,\n       34129.92 , 31696.83 , 33502.205, 35085.38 , 35052.05 , 33535.535,\n       32602.295, 32746.725, 33657.745, 33246.675, 33152.24 , 40223.755,\n       36329.7  , 37196.28 , 38185.07 , 33407.77 , 32763.39 , 36196.38 ,\n       36857.425, 38546.145, 36051.95 , 36546.345, 32685.62 , 37374.04 ,\n       31457.965, 32974.48 , 34507.66 , 35524.225, 34035.485, 33952.16 ,\n       35540.89 , 34724.305, 29785.91 , 32235.665, 48772.9  , 19781.355,\n       27569.465, 21458.965, 27608.35 , 37124.065, 38973.88 , 34529.88 ,\n       32635.625, 27252.83 , 22986.59 , 40623.715, 36935.195, 37740.67 ,\n       35440.9  , 34568.765, 38707.24 , 36357.475, 30752.48 , 30663.6  ,\n       24264.24 , 29313.735, 25841.86 , 27775.   , 27108.4  , 29941.45 ,\n       31735.715, 33613.305, 27974.98 , 34402.115, 32702.285, 35946.405,\n       35579.775, 31924.585, 30291.415, 32507.86 , 33257.785, 35235.365,\n       35574.22 , 29713.695, 30724.705, 31569.065, 22986.59 , 31152.44 ,\n       31202.435, 38062.86 , 31980.135, 36979.635, 25708.54 , 28636.025,\n       25103.045, 35740.87 , 37674.01 , 29463.72 , 33091.135, 37907.32 ,\n       35613.105, 33363.33 , 31374.64 , 33902.165, 30913.575, 32752.28 ,\n       32424.535, 34452.11 , 34402.115, 35440.9  , 35263.14 , 37957.315,\n       35690.875, 35751.98 , 34485.44 , 36824.095, 35890.855, 34174.36 ,\n       32968.925, 31257.985, 32318.99 , 35585.33 , 34546.545, 36024.175,\n       32518.97 , 35879.745, 35224.255, 34724.305, 34357.675, 35646.435,\n       37490.695, 36968.525, 34979.835, 41068.115, 37374.04 , 36246.375,\n       33196.68 , 32974.48 , 35002.055, 33779.955, 37224.055, 35418.68 ,\n       35090.935, 36179.715, 34490.995, 31991.245, 33063.36 , 33346.665,\n       32918.93 , 31735.715, 34257.685, 34602.095, 35757.535, 38773.9  ,\n       30146.985, 34229.91 , 36018.62 , 29463.72 , 34357.675, 34602.095,\n       34674.31 , 37496.25 , 39223.855, 32007.91 , 32613.405, 35063.16 ,\n       33963.27 , 32802.275, 30296.97 , 30074.77 , 28291.615, 33235.565,\n       33235.565, 31702.385, 32918.93 , 31496.85 , 29941.45 , 32185.67 ,\n       33435.545, 30935.795, 33479.985, 36624.115, 33996.6  , 38751.68 ,\n       37740.67 , 33496.65 ]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X,y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:584\u001b[0m, in \u001b[0;36mLinearDiscriminantAnalysis.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    579\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    581\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    582\u001b[0m     X, y, ensure_min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m[xp\u001b[38;5;241m.\u001b[39mfloat64, xp\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m    583\u001b[0m )\n\u001b[1;32m--> 584\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m unique_labels(y)\n\u001b[0;32m    585\u001b[0m n_samples, _ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    586\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:104\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    102\u001b[0m _unique_labels \u001b[38;5;241m=\u001b[39m _FN_UNIQUE_LABELS\u001b[38;5;241m.\u001b[39mget(label_type, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _unique_labels:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mrepr\u001b[39m(ys))\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_array_api_compliant:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# array_api does not allow for mixed dtypes\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     unique_ys \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mconcat([_unique_labels(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ys])\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (array([36524.125, 35668.655, 39912.675, 38873.89 , 39701.585, 35718.65 ,\n       33396.66 , 34285.46 , 31280.205, 33352.22 , 35424.235, 33379.995,\n       32713.395, 33046.695, 33863.28 , 32407.87 , 32968.925, 33274.45 ,\n       30308.08 , 31813.485, 30941.35 , 33135.575, 34118.81 , 32291.215,\n       32907.82 , 31102.445, 32291.215, 33591.085, 36079.725, 37074.07 ,\n       31735.715, 33729.96 , 33052.25 , 31669.055, 33863.28 , 32957.815,\n       32446.755, 32496.75 , 33141.13 , 36635.225, 39018.32 , 37607.35 ,\n       34268.795, 34502.105, 33713.295, 31563.51 , 32141.23 , 33496.65 ,\n       29991.445, 31119.11 , 33124.465, 33968.825, 36168.605, 33318.89 ,\n       32707.84 , 40268.195, 35457.565, 37862.88 , 34135.475, 32924.485,\n       31891.255, 33141.13 , 35863.08 , 37562.91 , 39462.72 , 34940.95 ,\n       32146.785, 32652.29 , 31074.67 , 32691.175, 35646.435, 33113.355,\n       33691.075, 34690.975, 34846.515, 34918.73 , 34879.845, 34107.7  ,\n       34618.76 , 32630.07 , 37368.485, 36768.545, 35007.61 , 34257.685,\n       35490.895, 36829.65 , 33413.325, 34002.155, 38923.885, 39323.845,\n       35646.435, 35579.775, 35785.31 , 34502.105, 34713.195, 36801.875,\n       34235.465, 44823.295, 43440.1  , 41195.88 , 37368.485, 37668.455,\n       35579.775, 34091.035, 34257.685, 32502.305, 32418.98 , 34035.485,\n       35963.07 , 34602.095, 34413.225, 37301.825, 32846.715, 33841.06 ,\n       34740.97 , 32930.04 , 34307.68 , 33446.655, 32618.96 , 31835.705,\n       32607.85 , 33352.22 , 33113.355, 32530.08 , 32657.845, 33252.23 ,\n       31180.215, 31624.615, 35724.205, 31313.535, 35874.19 , 35140.93 ,\n       35396.46 , 32341.21 , 31980.135, 35190.925, 33007.81 , 35851.97 ,\n       32535.635, 34168.805, 34296.57 , 27880.545, 30013.665, 30374.74 ,\n       27236.165, 34052.15 , 31263.54 , 27363.93 , 28808.23 , 31091.335,\n       34007.71 , 30019.22 , 27841.66 , 31713.495, 34046.595, 34174.36 ,\n       29285.96 , 38568.365, 33696.63 , 36163.05 , 34718.75 , 41601.395,\n       43340.11 , 46523.125, 32518.97 , 33891.055, 44045.595, 32646.735,\n       35102.045, 35563.11 , 32635.625, 32663.4  , 30952.46 , 35640.88 ,\n       32546.745, 36363.03 , 33441.1  , 35079.825, 38107.3  , 38773.9  ,\n       43134.575, 34129.92 , 39746.025, 36457.465, 31130.22 , 34179.915,\n       43501.205, 37674.01 , 36418.58 , 39912.675, 38612.805, 37435.145,\n       39873.79 , 37774.   , 36685.22 , 43745.625, 40479.285, 39479.385,\n       40407.07 , 38746.125, 39634.925, 34229.91 , 42273.55 , 43623.415,\n       44628.87 , 32724.505, 35140.93 , 32124.565, 33685.52 , 29685.92 ,\n       33107.8  , 30019.22 , 32257.885, 35413.125, 30063.66 , 34341.01 ,\n       32707.84 , 36896.31 , 33057.805, 35402.015, 38612.805, 34241.02 ,\n       38212.845, 36762.99 , 45917.63 , 48467.375, 44662.2  , 39790.465,\n       42695.73 , 36396.36 , 33224.455, 41173.66 , 46312.035, 45812.085,\n       37362.93 , 33807.73 , 36835.205, 40873.69 , 36001.955, 36696.33 ,\n       38312.835, 33857.725, 35318.69 , 35513.115, 31069.115, 31135.775,\n       33929.94 , 34585.43 , 35735.315, 37318.49 , 36035.285, 35763.09 ,\n       38646.135, 45878.745, 33929.94 , 32641.18 , 41406.97 , 48350.72 ,\n       40734.815, 38007.31 , 40012.665, 41773.6  , 46650.89 , 40701.485,\n       40029.33 , 30885.8  , 38962.77 , 46089.835, 41495.85 , 32885.6  ,\n       32530.08 , 34663.2  , 36318.59 , 42723.505, 37540.69 , 38073.97 ,\n       40368.185, 37918.43 , 36007.51 , 37840.66 , 43440.1  , 38707.24 ,\n       42467.975, 44012.265, 39373.84 , 35846.415, 34607.65 , 34490.995,\n       35079.825, 36468.575, 38112.855, 39707.14 , 36829.65 , 34035.485,\n       33379.995, 37096.29 , 36379.695, 32163.45 , 35246.475, 39112.755,\n       38168.405, 36607.45 , 36079.725, 38785.01 , 40195.98 , 36751.88 ,\n       41218.1  , 38046.195, 36857.425, 33174.46 , 27625.015, 34007.71 ,\n       33457.765, 34807.63 , 36479.685, 31691.275, 32852.27 , 32119.01 ,\n       35452.01 , 33957.715, 35696.43 , 35418.68 , 33557.755, 31707.94 ,\n       35635.325, 35724.205, 35063.16 , 33791.065, 32596.74 , 35179.815,\n       34129.92 , 31696.83 , 33502.205, 35085.38 , 35052.05 , 33535.535,\n       32602.295, 32746.725, 33657.745, 33246.675, 33152.24 , 40223.755,\n       36329.7  , 37196.28 , 38185.07 , 33407.77 , 32763.39 , 36196.38 ,\n       36857.425, 38546.145, 36051.95 , 36546.345, 32685.62 , 37374.04 ,\n       31457.965, 32974.48 , 34507.66 , 35524.225, 34035.485, 33952.16 ,\n       35540.89 , 34724.305, 29785.91 , 32235.665, 48772.9  , 19781.355,\n       27569.465, 21458.965, 27608.35 , 37124.065, 38973.88 , 34529.88 ,\n       32635.625, 27252.83 , 22986.59 , 40623.715, 36935.195, 37740.67 ,\n       35440.9  , 34568.765, 38707.24 , 36357.475, 30752.48 , 30663.6  ,\n       24264.24 , 29313.735, 25841.86 , 27775.   , 27108.4  , 29941.45 ,\n       31735.715, 33613.305, 27974.98 , 34402.115, 32702.285, 35946.405,\n       35579.775, 31924.585, 30291.415, 32507.86 , 33257.785, 35235.365,\n       35574.22 , 29713.695, 30724.705, 31569.065, 22986.59 , 31152.44 ,\n       31202.435, 38062.86 , 31980.135, 36979.635, 25708.54 , 28636.025,\n       25103.045, 35740.87 , 37674.01 , 29463.72 , 33091.135, 37907.32 ,\n       35613.105, 33363.33 , 31374.64 , 33902.165, 30913.575, 32752.28 ,\n       32424.535, 34452.11 , 34402.115, 35440.9  , 35263.14 , 37957.315,\n       35690.875, 35751.98 , 34485.44 , 36824.095, 35890.855, 34174.36 ,\n       32968.925, 31257.985, 32318.99 , 35585.33 , 34546.545, 36024.175,\n       32518.97 , 35879.745, 35224.255, 34724.305, 34357.675, 35646.435,\n       37490.695, 36968.525, 34979.835, 41068.115, 37374.04 , 36246.375,\n       33196.68 , 32974.48 , 35002.055, 33779.955, 37224.055, 35418.68 ,\n       35090.935, 36179.715, 34490.995, 31991.245, 33063.36 , 33346.665,\n       32918.93 , 31735.715, 34257.685, 34602.095, 35757.535, 38773.9  ,\n       30146.985, 34229.91 , 36018.62 , 29463.72 , 34357.675, 34602.095,\n       34674.31 , 37496.25 , 39223.855, 32007.91 , 32613.405, 35063.16 ,\n       33963.27 , 32802.275, 30296.97 , 30074.77 , 28291.615, 33235.565,\n       33235.565, 31702.385, 32918.93 , 31496.85 , 29941.45 , 32185.67 ,\n       33435.545, 30935.795, 33479.985, 36624.115, 33996.6  , 38751.68 ,\n       37740.67 , 33496.65 ]),)"
     ]
    }
   ],
   "source": [
    "cls.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2a9d79c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearDiscriminantAnalysis' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:752\u001b[0m, in \u001b[0;36mLinearDiscriminantAnalysis.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Apply decision function to an array of samples.\u001b[39;00m\n\u001b[0;32m    733\u001b[0m \n\u001b[0;32m    734\u001b[0m \u001b[38;5;124;03mThe decision function is equal (up to a constant factor) to the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;124;03m    log likelihood ratio of the positive class.\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;66;03m# Only override for the doc\u001b[39;00m\n\u001b[1;32m--> 752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdecision_function(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:433\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LinearDiscriminantAnalysis' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "pred = cls.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e9fa4719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>resid_area</th>\n",
       "      <th>air_qual</th>\n",
       "      <th>room_num</th>\n",
       "      <th>age</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>dist3</th>\n",
       "      <th>dist4</th>\n",
       "      <th>teachers</th>\n",
       "      <th>poor_prop</th>\n",
       "      <th>airport</th>\n",
       "      <th>n_hos_beds</th>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <th>waterbody</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>bus_ter</th>\n",
       "      <th>parks</th>\n",
       "      <th>Sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>32.31</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.35</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.18</td>\n",
       "      <td>4.01</td>\n",
       "      <td>24.7</td>\n",
       "      <td>4.98</td>\n",
       "      <td>YES</td>\n",
       "      <td>5.480</td>\n",
       "      <td>11.1920</td>\n",
       "      <td>River</td>\n",
       "      <td>23</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.049347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "      <td>37.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.99</td>\n",
       "      <td>4.70</td>\n",
       "      <td>5.12</td>\n",
       "      <td>5.06</td>\n",
       "      <td>22.2</td>\n",
       "      <td>9.14</td>\n",
       "      <td>NO</td>\n",
       "      <td>7.332</td>\n",
       "      <td>12.1728</td>\n",
       "      <td>Lake</td>\n",
       "      <td>42</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.046146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "      <td>37.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.86</td>\n",
       "      <td>5.01</td>\n",
       "      <td>4.97</td>\n",
       "      <td>22.2</td>\n",
       "      <td>4.03</td>\n",
       "      <td>NO</td>\n",
       "      <td>7.394</td>\n",
       "      <td>101.1200</td>\n",
       "      <td>None</td>\n",
       "      <td>38</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.045764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "      <td>32.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.21</td>\n",
       "      <td>5.93</td>\n",
       "      <td>6.16</td>\n",
       "      <td>5.96</td>\n",
       "      <td>21.3</td>\n",
       "      <td>2.94</td>\n",
       "      <td>YES</td>\n",
       "      <td>9.268</td>\n",
       "      <td>11.2672</td>\n",
       "      <td>Lake</td>\n",
       "      <td>45</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.047151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "      <td>32.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.16</td>\n",
       "      <td>5.86</td>\n",
       "      <td>6.37</td>\n",
       "      <td>5.86</td>\n",
       "      <td>21.3</td>\n",
       "      <td>5.33</td>\n",
       "      <td>NO</td>\n",
       "      <td>8.824</td>\n",
       "      <td>11.2896</td>\n",
       "      <td>Lake</td>\n",
       "      <td>55</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  resid_area  air_qual  room_num   age  dist1  dist2  dist3  dist4  \\\n",
       "0   24.0       32.31     0.538     6.575  65.2   4.35   3.81   4.18   4.01   \n",
       "1   21.6       37.07     0.469     6.421  78.9   4.99   4.70   5.12   5.06   \n",
       "2   34.7       37.07     0.469     7.185  61.1   5.03   4.86   5.01   4.97   \n",
       "3   33.4       32.18     0.458     6.998  45.8   6.21   5.93   6.16   5.96   \n",
       "4   36.2       32.18     0.458     7.147  54.2   6.16   5.86   6.37   5.86   \n",
       "\n",
       "   teachers  poor_prop airport  n_hos_beds  n_hot_rooms waterbody  rainfall  \\\n",
       "0      24.7       4.98     YES       5.480      11.1920     River        23   \n",
       "1      22.2       9.14      NO       7.332      12.1728      Lake        42   \n",
       "2      22.2       4.03      NO       7.394     101.1200      None        38   \n",
       "3      21.3       2.94     YES       9.268      11.2672      Lake        45   \n",
       "4      21.3       5.33      NO       8.824      11.2896      Lake        55   \n",
       "\n",
       "  bus_ter     parks  Sold  \n",
       "0     YES  0.049347     0  \n",
       "1     YES  0.046146     1  \n",
       "2     YES  0.045764     0  \n",
       "3     YES  0.047151     0  \n",
       "4     YES  0.039474     0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c01a2772",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'NO'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     11\u001b[0m logistic_model \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m logistic_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     14\u001b[0m lda_model \u001b[38;5;241m=\u001b[39m LinearDiscriminantAnalysis()\n\u001b[0;32m     15\u001b[0m lda_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1207\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1205\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1207\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1208\u001b[0m     X,\n\u001b[0;32m   1209\u001b[0m     y,\n\u001b[0;32m   1210\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1211\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_dtype,\n\u001b[0;32m   1212\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1213\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1214\u001b[0m )\n\u001b[0;32m   1215\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    921\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'NO'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X = df.loc[:, df.columns != 'Sold']  # Use square brackets [] instead of parentheses ()\n",
    "y = df['Sold']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X_train, y_train)\n",
    "\n",
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "lda_predictions = lda_model.predict(X_test)\n",
    "\n",
    "logistic_confusion_matrix = confusion_matrix(y_test, logistic_predictions)\n",
    "lda_confusion_matrix = confusion_matrix(y_test, lda_predictions)\n",
    "\n",
    "print(\"Confusion Matrix for Logistic Regression:\")\n",
    "print(logistic_confusion_matrix)\n",
    "\n",
    "print(\"\\nConfusion Matrix for Linear Discriminant Analysis (LDA):\")\n",
    "print(lda_confusion_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
